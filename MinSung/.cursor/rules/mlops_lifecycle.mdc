---
# 이 규칙 파일의 메타데이터입니다.
description: "MLOps 수명 주기 스터디를 위한 종합 규칙. 프로젝트 설정, 데이터 처리, 모델 학습, 배포, 모니터링, 자동화까지 모든 단계를 포괄합니다."
globs:
  - "**/*.py"          # 모든 파이썬 파일
  - "**/Dockerfile"     # Dockerfile
  - "**/*.{yaml,yml}" # YAML 설정 파일 (dvc.yaml, params.yaml 등)
  - "**/*.tf"          # Terraform 파일
  - "**/README.md"      # README 파일
alwaysApply: true
---

# MLOps Lifecycle Study Rules
이 규칙은 AI가 MLOps 프로젝트의 모든 단계에서 최적의 코드와 구조를 제안하도록 안내합니다.

---

## 📜 1. 프로젝트 설정 및 공통 규칙 (Project Setup & General Rules)
> 모든 코드와 문서의 기본이 되는 규칙입니다.

- **Python 버전**: 모든 Python 코드는 `Python 3.10` 이상을 기준으로 작성합니다.
- **언어 및 명명 규칙**: 모든 코드(변수, 함수, 클래스)와 문서(주석, Docstring)는 **영어로 작성**하는 것을 원칙으로 합니다.
- **코드 포맷터**: 코드 스타일은 **Black** 포맷터를 사용하여 일관성을 유지합니다.
- **린터(Linter)**: **Ruff**를 사용하여 코드를 정적으로 분석하고 잠재적인 오류를 수정합니다.
- **타입 힌팅 (Mandatory)**: 모든 함수의 인자(argument)와 반환 값(return value)에는 **반드시 타입 힌트를 명시**해야 합니다. 변수 선언 시에도 타입 힌트 사용을 권장합니다.
- **문서화 (Docstrings)**: 모든 공개(public) 함수, 클래스, 모듈에는 **Google 스타일 Docstring**을 작성하여 목적, 인자, 반환 값을 상세히 설명해야 합니다.
- **로깅 (Logging)**: 디버깅이나 정보 출력을 위해 `print()` 함수를 사용하지 않습니다. 대신 Python의 `logging` 모듈을 설정하여 사용하세요. 로그 레벨(DEBUG, INFO, WARNING, ERROR)을 명확히 구분하여 기록합니다.
- **의존성 관리**: 프로젝트의 Python 의존성은 `requirements.txt` 대신 `pyproject.toml` 파일을 사용하여 관리합니다.
- **프로젝트 설명**: `README.md` 파일에는 다음 섹션을 반드시 포함하여 프로젝트를 설명해야 합니다:
  - `## Project Overview`: 프로젝트의 목적과 비즈니스 문제 정의.
  - `## MLOps Lifecycle`: 이 프로젝트에서 구현한 MLOps 파이프라인 구조 설명.
  - `## How to Run`: 프로젝트를 설치하고 실행하는 방법에 대한 상세 가이드.

---

## 💾 2. 데이터 관리 및 처리 (Data Management & Processing)
> 재현 가능하고 안정적인 데이터 파이프라인을 위한 규칙입니다.

- **데이터 버전 관리 (DVC)**: 원시 데이터(raw data), 처리된 데이터(processed data), 피처(features)는 **DVC (Data Version Control)**를 사용하여 버전을 관리합니다. Git LFS나 Git에 직접 데이터를 커밋하지 마세요.
  - 명령어 예시: `dvc add data/raw/my_data.csv`
- **데이터 처리 파이프라인**: 데이터 처리 관련 코드는 `src/data/` 디렉토리 내에 모듈화된 스크립트(`.py`)로 작성하세요. Jupyter Notebook에서 작성한 실험 코드는 반드시 스크립트로 리팩토링해야 합니다.
- **경로 관리**: 파일 경로는 하드코딩하지 마세요. `pathlib` 라이브러리를 사용하여 운영체제에 독립적인 경로를 생성합니다.
- **설정 파일 분리**: 데이터 경로, 피처 목록 등 설정 값은 코드에서 분리하여 `params.yaml` 또는 `config/config.yaml` 파일에 정의하고 불러와서 사용합니다.

---

## 🧪 3. 모델 학습 및 실험 추적 (Model Experiment & Training)
> 모든 실험을 추적하고 비교하여 최적의 모델을 찾기 위한 규칙입니다.

- **실험 추적 도구 (MLflow)**: 모든 모델 학습 및 평가 과정은 **MLflow Tracking**을 사용하여 기록해야 합니다.
  - 모든 학습 코드는 `with mlflow.start_run():` 블록 내에서 실행되어야 합니다.
- **파라미터 로깅**: 학습에 사용된 하이퍼파라미터(예: learning rate, batch size)는 `mlflow.log_param()` 또는 `mlflow.log_params()`를 사용하여 기록합니다.
- **메트릭 로깅**: 모델의 성능 지표(예: Accuracy, RMSE, F1-score)는 `mlflow.log_metric()`을 사용하여 각 epoch 또는 학습 종료 시점에 기록합니다.
- **모델 아티팩트 저장**: 학습된 모델 객체, 시각화 자료 등은 `mlflow.sklearn.log_model()`, `mlflow.log_artifact()` 등의 함수를 사용하여 MLflow 서버에 저장합니다.

---

## 🚀 4. 모델 배포 및 서빙 (Model Deployment & Serving)
> 학습된 모델을 안정적인 서비스로 만들기 위한 규칙입니다.

- **API 프레임워크 (FastAPI)**: 모델을 서빙하는 REST API는 **FastAPI**를 사용하여 비동기(async) 방식으로 구현합니다.
- **데이터 유효성 검사 (Pydantic)**: API의 요청(Request) 및 응답(Response) 데이터 구조는 **Pydantic** 모델을 사용하여 명확하게 정의하고, 자동으로 데이터 유효성을 검사하도록 합니다.
- **컨테이너화 (Docker)**: API 애플리케이션은 **Dockerfile**을 작성하여 컨테이너화합니다.
  - **다단계 빌드 (Multi-stage Build)**를 사용하여 최종 이미지의 크기를 최적화하고 보안을 강화하세요.
  - 예: `builder` 단계에서 의존성을 설치하고, 최종 `runner` 단계에서는 필요한 파일만 복사합니다.

---

## 🔄 5. CI/CD 및 자동화 (Automation)
> 코드 변경 시 자동으로 테스트, 빌드, 배포하는 파이프라인 규칙입니다.

- **자동화 도구 (GitHub Actions)**: CI/CD 파이프라인은 **GitHub Actions**를 사용하여 구축합니다. 워크플로우 파일은 `.github/workflows/` 디렉토리에 위치시킵니다.
- **CI 파이프라인**: Pull Request가 생성되거나 main 브랜치에 푸시될 때 다음 작업이 자동으로 실행되어야 합니다.
  - **Linting & Formatting Check**: `ruff`와 `black --check`를 실행하여 코드 스타일 준수 여부를 검사합니다.
  - **Unit Tests**: `pytest`를 사용하여 단위 테스트를 실행합니다.
- **CD 파이프라인**: main 브랜치에 병합(merge)되면 다음 작업이 자동으로 실행되도록 제안합니다.
  - **Docker 이미지 빌드 및 푸시**: Docker 이미지를 빌드하여 Docker Hub 또는 ECR 같은 컨테이너 레지스트리에 푸시합니다.
  - **모델 재학습 트리거 (선택 사항)**: 특정 조건(예: 새로운 데이터 태그)이 만족되면 모델 재학습 파이프라인을 트리거합니다.

---

## 📊 6. 모델 모니터링 (Monitoring)
> 배포된 모델이 안정적으로 운영되는지 감시하기 위한 규칙입니다.

- **API 로깅**: FastAPI에 **로깅 미들웨어**를 추가하여 모든 요청, 응답 및 예측 결과를 구조화된 로그(JSON 형식 권장)로 기록합니다.
- **성능 모니터링**: 모델의 예측 성능(business metrics)과 기술적 성능(latency, error rate)을 주기적으로 측정하는 스크립트를 `src/monitoring/` 디렉토리에 작성하세요.
- **데이터 드리프트 탐지**: 프로덕션 환경의 입력 데이터 분포가 학습 시점의 데이터 분포와 달라지는 현상(Data Drift)을 탐지하는 로직을 구현합니다. `evidently.ai` 또는 `scipy.stats` 같은 라이브러리 사용을 권장합니다.