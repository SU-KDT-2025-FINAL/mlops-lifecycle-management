# MLOps ë„êµ¬ ë¹„êµ ê°€ì´ë“œ: ìµœì ì˜ ë„êµ¬ ì„ íƒí•˜ê¸°

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ì‹¤í—˜ ê´€ë¦¬ ë„êµ¬](#ì‹¤í—˜-ê´€ë¦¬-ë„êµ¬)
3. [ë°ì´í„° ê´€ë¦¬ ë„êµ¬](#ë°ì´í„°-ê´€ë¦¬-ë„êµ¬)
4. [ëª¨ë¸ ë°°í¬ ë„êµ¬](#ëª¨ë¸-ë°°í¬-ë„êµ¬)
5. [ëª¨ë‹ˆí„°ë§ ë„êµ¬](#ëª¨ë‹ˆí„°ë§-ë„êµ¬)
6. [ì¢…í•© ë¹„êµ](#ì¢…í•©-ë¹„êµ)
7. [ì„ íƒ ê°€ì´ë“œ](#ì„ íƒ-ê°€ì´ë“œ)

---

## ğŸ¯ ê°œìš”

MLOps ìƒíƒœê³„ëŠ” ë‹¤ì–‘í•œ ë„êµ¬ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê°ê°ì˜ ë„êµ¬ëŠ” íŠ¹ì • ì˜ì—­ì—ì„œ ê°•ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê°€ì´ë“œëŠ” ì£¼ìš” MLOps ë„êµ¬ë“¤ì„ ë¹„êµ ë¶„ì„í•˜ì—¬ í”„ë¡œì íŠ¸ì— ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.

---

## ğŸ§ª ì‹¤í—˜ ê´€ë¦¬ ë„êµ¬

### 1. MLflow

**ê°œìš”**: Apacheì—ì„œ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ì‹¤í—˜ ê´€ë¦¬ í”Œë«í¼

**ì¥ì **:
- âœ… ì˜¤í”ˆì†ŒìŠ¤ (ë¬´ë£Œ)
- âœ… ë‹¤ì–‘í•œ ML ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì›
- âœ… ë¡œì»¬ ë° í´ë¼ìš°ë“œ ë°°í¬ ê°€ëŠ¥
- âœ… í’ë¶€í•œ API
- âœ… í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°

**ë‹¨ì **:
- âŒ UIê°€ ìƒëŒ€ì ìœ¼ë¡œ ë‹¨ìˆœ
- âŒ ê³ ê¸‰ í˜‘ì—… ê¸°ëŠ¥ ë¶€ì¡±
- âŒ í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì—†ìŒ (ì§ì ‘ í˜¸ìŠ¤íŒ… í•„ìš”)

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# MLflow ê¸°ë³¸ ì‚¬ìš©ë²•
import mlflow
import mlflow.sklearn

# ì‹¤í—˜ ì„¤ì •
mlflow.set_experiment("my_experiment")

with mlflow.start_run():
    # íŒŒë¼ë¯¸í„° ë¡œê¹…
    mlflow.log_param("learning_rate", 0.01)
    mlflow.log_param("max_depth", 10)
    
    # ëª¨ë¸ í•™ìŠµ
    model = RandomForestClassifier(n_estimators=100)
    model.fit(X_train, y_train)
    
    # ë©”íŠ¸ë¦­ ë¡œê¹…
    accuracy = model.score(X_test, y_test)
    mlflow.log_metric("accuracy", accuracy)
    
    # ëª¨ë¸ ì €ì¥
    mlflow.sklearn.log_model(model, "model")
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

### 2. Weights & Biases (W&B)

**ê°œìš”**: ì‹¤í—˜ ì¶”ì ê³¼ í˜‘ì—…ì— íŠ¹í™”ëœ í´ë¼ìš°ë“œ ê¸°ë°˜ í”Œë«í¼

**ì¥ì **:
- âœ… ì§ê´€ì ì´ê³  ê°•ë ¥í•œ UI
- âœ… íŒ€ í˜‘ì—… ê¸°ëŠ¥ ìš°ìˆ˜
- âœ… ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
- âœ… ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- âœ… ëª¨ë¸ ë²„ì „ ê´€ë¦¬

**ë‹¨ì **:
- âŒ ìœ ë£Œ ì„œë¹„ìŠ¤ (ê°œì¸ ì‚¬ìš©ì ë¬´ë£Œ)
- âŒ ë°ì´í„°ê°€ í´ë¼ìš°ë“œì— ì €ì¥
- âŒ ì˜¤í”„ë¼ì¸ ì‚¬ìš© ì œí•œ

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# W&B ê¸°ë³¸ ì‚¬ìš©ë²•
import wandb

# í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
wandb.init(project="my_ml_project")

# ì„¤ì • ë¡œê¹…
wandb.config.update({
    "learning_rate": 0.01,
    "batch_size": 32,
    "epochs": 100
})

# ëª¨ë¸ í•™ìŠµ
for epoch in range(100):
    train_loss = train_epoch()
    val_loss = validate_epoch()
    
    # ë©”íŠ¸ë¦­ ë¡œê¹…
    wandb.log({
        "train_loss": train_loss,
        "val_loss": val_loss,
        "epoch": epoch
    })

# ëª¨ë¸ ì €ì¥
wandb.save("model.h5")
```

**ë¹„ìš©**: 
- ê°œì¸: ë¬´ë£Œ (ì œí•œì )
- íŒ€: $50/ì›”/ì‚¬ìš©ì
- ì—”í„°í”„ë¼ì´ì¦ˆ: ë§ì¶¤í˜•

### 3. Kubeflow

**ê°œìš”**: Kubernetes ê¸°ë°˜ì˜ ML ì›Œí¬í”Œë¡œìš° í”Œë«í¼

**ì¥ì **:
- âœ… í™•ì¥ì„± ìš°ìˆ˜
- âœ… ì»¨í…Œì´ë„ˆ ê¸°ë°˜
- âœ… ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ ì§€ì›
- âœ… í´ë¼ìš°ë“œ ë„¤ì´í‹°ë¸Œ
- âœ… ì˜¤í”ˆì†ŒìŠ¤

**ë‹¨ì **:
- âŒ ë³µì¡í•œ ì„¤ì •
- âŒ í•™ìŠµ ê³¡ì„  ê°€íŒŒë¦„
- âŒ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ë†’ìŒ
- âŒ ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§ ê°€ëŠ¥ì„±

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# Kubeflow íŒŒì´í”„ë¼ì¸ ì˜ˆì‹œ
from kfp import dsl

@dsl.pipeline(
    name="ML Training Pipeline",
    description="End-to-end ML training pipeline"
)
def ml_training_pipeline():
    # ë°ì´í„° ì „ì²˜ë¦¬
    preprocess_op = dsl.ContainerOp(
        name="preprocess",
        image="preprocess:latest",
        arguments=["--input", "/data/raw", "--output", "/data/processed"]
    )
    
    # ëª¨ë¸ í•™ìŠµ
    train_op = dsl.ContainerOp(
        name="train",
        image="train:latest",
        arguments=["--data", "/data/processed", "--model", "/models/model.pkl"]
    ).after(preprocess_op)
    
    # ëª¨ë¸ í‰ê°€
    evaluate_op = dsl.ContainerOp(
        name="evaluate",
        image="evaluate:latest",
        arguments=["--model", "/models/model.pkl", "--data", "/data/test"]
    ).after(train_op)
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤, ì¸í”„ë¼ ë¹„ìš© ë³„ë„)

---

## ğŸ’¾ ë°ì´í„° ê´€ë¦¬ ë„êµ¬

### 1. DVC (Data Version Control)

**ê°œìš”**: Gitê³¼ ìœ ì‚¬í•œ ë°ì´í„° ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ

**ì¥ì **:
- âœ… Gitê³¼ ì™„ë²½ í†µí•©
- âœ… ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬
- âœ… ë‹¤ì–‘í•œ ìŠ¤í† ë¦¬ì§€ ë°±ì—”ë“œ
- âœ… íŒŒì´í”„ë¼ì¸ ê´€ë¦¬
- âœ… ì˜¤í”ˆì†ŒìŠ¤

**ë‹¨ì **:
- âŒ í•™ìŠµ ê³¡ì„ 
- âŒ ê³ ê¸‰ ë°ì´í„° í’ˆì§ˆ ê¸°ëŠ¥ ë¶€ì¡±
- âŒ ì‹¤ì‹œê°„ í˜‘ì—… ê¸°ëŠ¥ ì œí•œ

**ì‚¬ìš© ì‚¬ë¡€**:
```bash
# DVC ê¸°ë³¸ ì‚¬ìš©ë²•
# ë°ì´í„° ì¶”ê°€
dvc add data/raw/dataset.csv

# íŒŒì´í”„ë¼ì¸ ìƒì„±
dvc run -n preprocess \
    -d data/raw/dataset.csv \
    -d src/preprocess.py \
    -o data/processed/ \
    python src/preprocess.py

# ì›ê²© ì €ì¥ì†Œ ì„¤ì •
dvc remote add -d myremote s3://my-bucket/dvc
dvc push
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

### 2. Apache Airflow

**ê°œìš”**: ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ í”Œë«í¼

**ì¥ì **:
- âœ… ê°•ë ¥í•œ ìŠ¤ì¼€ì¤„ë§
- âœ… ë³µì¡í•œ ì˜ì¡´ì„± ê´€ë¦¬
- âœ… ë‹¤ì–‘í•œ ì—°ì‚°ì ì§€ì›
- âœ… í™•ì¥ì„± ìš°ìˆ˜
- âœ… ì˜¤í”ˆì†ŒìŠ¤

**ë‹¨ì **:
- âŒ ë³µì¡í•œ ì„¤ì •
- âŒ ML íŠ¹í™” ê¸°ëŠ¥ ë¶€ì¡±
- âŒ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­ ë†’ìŒ
- âŒ UI ê°œì„  í•„ìš”

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# Airflow DAG ì˜ˆì‹œ
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'ml_team',
    'depends_on_past': False,
    'start_date': datetime(2023, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'ml_pipeline',
    default_args=default_args,
    description='ML training pipeline',
    schedule_interval=timedelta(days=1),
)

def preprocess_data():
    # ë°ì´í„° ì „ì²˜ë¦¬ ë¡œì§
    pass

def train_model():
    # ëª¨ë¸ í•™ìŠµ ë¡œì§
    pass

def evaluate_model():
    # ëª¨ë¸ í‰ê°€ ë¡œì§
    pass

preprocess_task = PythonOperator(
    task_id='preprocess_data',
    python_callable=preprocess_data,
    dag=dag,
)

train_task = PythonOperator(
    task_id='train_model',
    python_callable=train_model,
    dag=dag,
)

evaluate_task = PythonOperator(
    task_id='evaluate_model',
    python_callable=evaluate_model,
    dag=dag,
)

preprocess_task >> train_task >> evaluate_task
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

### 3. Great Expectations

**ê°œìš”**: ë°ì´í„° í’ˆì§ˆ ê²€ì¦ì— íŠ¹í™”ëœ ë„êµ¬

**ì¥ì **:
- âœ… ê°•ë ¥í•œ ë°ì´í„° ê²€ì¦
- âœ… ìë™í™”ëœ í…ŒìŠ¤íŠ¸
- âœ… ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ ì§€ì›
- âœ… ë¬¸ì„œí™” ìš°ìˆ˜
- âœ… ì˜¤í”ˆì†ŒìŠ¤

**ë‹¨ì **:
- âŒ í•™ìŠµ ê³¡ì„ 
- âŒ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì œí•œ
- âŒ ë³µì¡í•œ ì„¤ì •

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# Great Expectations ì‚¬ìš©ë²•
import great_expectations as ge

# ì»¨í…ìŠ¤íŠ¸ ìƒì„±
context = ge.get_context()

# ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •
datasource = context.get_datasource("my_datasource")

# ë°ì´í„° ê²€ì¦
batch = datasource.get_batch_list_from_batch_request(
    batch_request=BatchRequest(
        datasource_name="my_datasource",
        data_connector_name="default_inferred_data_connector_name",
        data_asset_name="my_data",
    )
)

# ê²€ì¦ ê·œì¹™ ì •ì˜
validator = context.get_validator(
    batch_request=batch,
    expectation_suite_name="my_suite"
)

# ê²€ì¦ ì‹¤í–‰
validator.expect_column_values_to_be_between(
    column="age", min_value=0, max_value=120
)
validator.expect_column_values_to_not_be_null(column="email")
validator.save_expectation_suite()
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

---

## ğŸš€ ëª¨ë¸ ë°°í¬ ë„êµ¬

### 1. FastAPI

**ê°œìš”**: ê³ ì„±ëŠ¥ Python ì›¹ í”„ë ˆì„ì›Œí¬

**ì¥ì **:
- âœ… ê³ ì„±ëŠ¥ (Starlette ê¸°ë°˜)
- âœ… ìë™ API ë¬¸ì„œí™”
- âœ… íƒ€ì… íŒíŒ… ì§€ì›
- âœ… ë¹„ë™ê¸° ì²˜ë¦¬
- âœ… ì‰¬ìš´ í•™ìŠµ ê³¡ì„ 

**ë‹¨ì **:
- âŒ ML íŠ¹í™” ê¸°ëŠ¥ ë¶€ì¡±
- âŒ ëª¨ë¸ ê´€ë¦¬ ê¸°ëŠ¥ ì œí•œ
- âŒ í™•ì¥ì„± ì œí•œ

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# FastAPI ëª¨ë¸ ì„œë¹™ ì˜ˆì‹œ
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib
import numpy as np

app = FastAPI(title="ML Model API")

class PredictionRequest(BaseModel):
    features: list[float]

class PredictionResponse(BaseModel):
    prediction: float
    confidence: float

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    try:
        # ëª¨ë¸ ë¡œë“œ
        model = joblib.load("model.pkl")
        
        # ì˜ˆì¸¡
        features = np.array(request.features).reshape(1, -1)
        prediction = model.predict(features)[0]
        confidence = model.predict_proba(features).max()
        
        return PredictionResponse(
            prediction=float(prediction),
            confidence=float(confidence)
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    return {"status": "healthy"}
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

### 2. TensorFlow Serving

**ê°œìš”**: TensorFlow ëª¨ë¸ì„ ìœ„í•œ í”„ë¡œë•ì…˜ ì„œë¹™ ì‹œìŠ¤í…œ

**ì¥ì **:
- âœ… TensorFlow ëª¨ë¸ ìµœì í™”
- âœ… ê³ ì„±ëŠ¥ ì¶”ë¡ 
- âœ… ëª¨ë¸ ë²„ì „ ê´€ë¦¬
- âœ… A/B í…ŒìŠ¤íŠ¸ ì§€ì›
- âœ… í™•ì¥ì„± ìš°ìˆ˜

**ë‹¨ì **:
- âŒ TensorFlow ëª¨ë¸ë§Œ ì§€ì›
- âŒ ë³µì¡í•œ ì„¤ì •
- âŒ í•™ìŠµ ê³¡ì„  ê°€íŒŒë¦„

**ì‚¬ìš© ì‚¬ë¡€**:
```bash
# TensorFlow Serving ì‹¤í–‰
tensorflow_model_server \
    --port=8500 \
    --rest_api_port=8501 \
    --model_name=my_model \
    --model_base_path=/models/my_model
```

```python
# í´ë¼ì´ì–¸íŠ¸ ì˜ˆì‹œ
import requests
import json

def predict_tf_serving(features):
    url = "http://localhost:8501/v1/models/my_model:predict"
    data = {"instances": [features]}
    response = requests.post(url, json=data)
    return response.json()
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

### 3. Seldon Core

**ê°œìš”**: Kubernetes ê¸°ë°˜ ML ëª¨ë¸ ë°°í¬ í”Œë«í¼

**ì¥ì **:
- âœ… ë‹¤ì–‘í•œ ML í”„ë ˆì„ì›Œí¬ ì§€ì›
- âœ… ê³ ê¸‰ ë°°í¬ ê¸°ëŠ¥
- âœ… A/B í…ŒìŠ¤íŠ¸ ë‚´ì¥
- âœ… ëª¨ë‹ˆí„°ë§ í†µí•©
- âœ… í™•ì¥ì„± ìš°ìˆ˜

**ë‹¨ì **:
- âŒ Kubernetes ì˜ì¡´ì„±
- âŒ ë³µì¡í•œ ì„¤ì •
- âŒ í•™ìŠµ ê³¡ì„  ê°€íŒŒë¦„

**ì‚¬ìš© ì‚¬ë¡€**:
```yaml
# Seldon Deployment ì˜ˆì‹œ
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: my-model
spec:
  name: my-model
  predictors:
  - name: default
    replicas: 1
    graph:
      name: classifier
      type: MODEL
      modelUri: s3://my-bucket/model
      envSecretRefName: seldon-init-container-secret
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë„êµ¬

### 1. Prometheus + Grafana

**ê°œìš”**: ì‹œê³„ì—´ ë°ì´í„° ìˆ˜ì§‘ ë° ì‹œê°í™” í”Œë«í¼

**ì¥ì **:
- âœ… ê°•ë ¥í•œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- âœ… í’ë¶€í•œ ì‹œê°í™”
- âœ… ì•Œë¦¼ ì‹œìŠ¤í…œ
- âœ… í™•ì¥ì„± ìš°ìˆ˜
- âœ… ì˜¤í”ˆì†ŒìŠ¤

**ë‹¨ì **:
- âŒ ML íŠ¹í™” ê¸°ëŠ¥ ë¶€ì¡±
- âŒ ë³µì¡í•œ ì„¤ì •
- âŒ í•™ìŠµ ê³¡ì„ 

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# Prometheus ë©”íŠ¸ë¦­ ìˆ˜ì§‘
from prometheus_client import Counter, Histogram, start_http_server
import time

# ë©”íŠ¸ë¦­ ì •ì˜
PREDICTION_COUNTER = Counter('model_predictions_total', 'Total predictions')
PREDICTION_DURATION = Histogram('prediction_duration_seconds', 'Prediction duration')

def predict_with_monitoring(features):
    start_time = time.time()
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    prediction = model.predict(features)
    
    # ë©”íŠ¸ë¦­ ê¸°ë¡
    duration = time.time() - start_time
    PREDICTION_COUNTER.inc()
    PREDICTION_DURATION.observe(duration)
    
    return prediction

# HTTP ì„œë²„ ì‹œì‘ (ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸)
start_http_server(8000)
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

### 2. Evidently AI

**ê°œìš”**: ML ëª¨ë¸ ëª¨ë‹ˆí„°ë§ì— íŠ¹í™”ëœ ë„êµ¬

**ì¥ì **:
- âœ… ML íŠ¹í™” ê¸°ëŠ¥
- âœ… ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€
- âœ… ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- âœ… ì‰¬ìš´ ì‚¬ìš©ë²•
- âœ… ì˜¤í”ˆì†ŒìŠ¤

**ë‹¨ì **:
- âŒ ì œí•œì ì¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•
- âŒ ê³ ê¸‰ ê¸°ëŠ¥ ë¶€ì¡±
- âŒ í™•ì¥ì„± ì œí•œ

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# Evidently AI ì‚¬ìš©ë²•
from evidently import ColumnMapping
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset

# ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€
data_drift_report = Report(metrics=[
    DataDriftPreset(),
])

data_drift_report.run(
    reference_data=reference_df,
    current_data=current_df,
    column_mapping=ColumnMapping(
        target='target',
        numerical_features=['feature1', 'feature2']
    )
)

# ê²°ê³¼ í™•ì¸
data_drift_report.show()
```

**ë¹„ìš©**: ë¬´ë£Œ (ì˜¤í”ˆì†ŒìŠ¤)

### 3. Weights & Biases (ëª¨ë‹ˆí„°ë§)

**ê°œìš”**: ì‹¤í—˜ ê´€ë¦¬ì™€ ëª¨ë‹ˆí„°ë§ì„ í†µí•©í•œ í”Œë«í¼

**ì¥ì **:
- âœ… í†µí•©ëœ í”Œë«í¼
- âœ… ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- âœ… ê°•ë ¥í•œ ì‹œê°í™”
- âœ… í˜‘ì—… ê¸°ëŠ¥
- âœ… ì•Œë¦¼ ì‹œìŠ¤í…œ

**ë‹¨ì **:
- âŒ ìœ ë£Œ ì„œë¹„ìŠ¤
- âŒ ë°ì´í„° í”„ë¼ì´ë²„ì‹œ ìš°ë ¤
- âŒ ì»¤ìŠ¤í„°ë§ˆì´ì§• ì œí•œ

**ì‚¬ìš© ì‚¬ë¡€**:
```python
# W&B ëª¨ë‹ˆí„°ë§ ì˜ˆì‹œ
import wandb

# ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™”
wandb.init(project="model_monitoring")

# ì˜ˆì¸¡ ë¡œê¹…
def log_prediction(features, prediction, actual=None):
    wandb.log({
        "prediction": prediction,
        "features": features,
        "actual": actual,
        "timestamp": wandb.run.timestamp
    })

# ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…
def log_performance_metrics(accuracy, precision, recall):
    wandb.log({
        "accuracy": accuracy,
        "precision": precision,
        "recall": recall
    })
```

**ë¹„ìš©**: 
- ê°œì¸: ë¬´ë£Œ (ì œí•œì )
- íŒ€: $50/ì›”/ì‚¬ìš©ì
- ì—”í„°í”„ë¼ì´ì¦ˆ: ë§ì¶¤í˜•

---

## ğŸ“ˆ ì¢…í•© ë¹„êµ

### ë„êµ¬ë³„ ë¹„êµí‘œ

| ë„êµ¬ | ìœ í˜• | ë¹„ìš© | í•™ìŠµ ê³¡ì„  | í™•ì¥ì„± | ML íŠ¹í™” | ì»¤ë®¤ë‹ˆí‹° |
|------|------|------|-----------|--------|----------|----------|
| **MLflow** | ì‹¤í—˜ ê´€ë¦¬ | ë¬´ë£Œ | ì¤‘ê°„ | ë†’ìŒ | ë†’ìŒ | í™œë°œí•¨ |
| **W&B** | ì‹¤í—˜ ê´€ë¦¬ | ìœ ë£Œ | ë‚®ìŒ | ë†’ìŒ | ë†’ìŒ | í™œë°œí•¨ |
| **Kubeflow** | ì›Œí¬í”Œë¡œìš° | ë¬´ë£Œ | ë†’ìŒ | ë§¤ìš° ë†’ìŒ | ë†’ìŒ | í™œë°œí•¨ |
| **DVC** | ë°ì´í„° ê´€ë¦¬ | ë¬´ë£Œ | ì¤‘ê°„ | ë†’ìŒ | ì¤‘ê°„ | í™œë°œí•¨ |
| **Airflow** | ì›Œí¬í”Œë¡œìš° | ë¬´ë£Œ | ë†’ìŒ | ë†’ìŒ | ë‚®ìŒ | í™œë°œí•¨ |
| **FastAPI** | ë°°í¬ | ë¬´ë£Œ | ë‚®ìŒ | ì¤‘ê°„ | ë‚®ìŒ | í™œë°œí•¨ |
| **Prometheus** | ëª¨ë‹ˆí„°ë§ | ë¬´ë£Œ | ë†’ìŒ | ë†’ìŒ | ë‚®ìŒ | í™œë°œí•¨ |
| **Evidently** | ëª¨ë‹ˆí„°ë§ | ë¬´ë£Œ | ë‚®ìŒ | ì¤‘ê°„ | ë†’ìŒ | ì„±ì¥ì¤‘ |

### ì‚¬ìš© ì‚¬ë¡€ë³„ ì¶”ì²œ

#### 1. ìŠ¤íƒ€íŠ¸ì—…/ì†Œê·œëª¨ íŒ€
**ì¶”ì²œ ìŠ¤íƒ**:
- ì‹¤í—˜ ê´€ë¦¬: MLflow
- ë°ì´í„° ê´€ë¦¬: DVC
- ë°°í¬: FastAPI
- ëª¨ë‹ˆí„°ë§: Evidently AI

**ì´ìœ **: ë¹„ìš© íš¨ìœ¨ì , í•™ìŠµ ê³¡ì„  ì™„ë§Œ, ì¶©ë¶„í•œ ê¸°ëŠ¥

#### 2. ì¤‘ê°„ ê·œëª¨ íŒ€
**ì¶”ì²œ ìŠ¤íƒ**:
- ì‹¤í—˜ ê´€ë¦¬: W&B
- ë°ì´í„° ê´€ë¦¬: DVC + Airflow
- ë°°í¬: FastAPI + Docker
- ëª¨ë‹ˆí„°ë§: Prometheus + Grafana

**ì´ìœ **: í˜‘ì—… ê¸°ëŠ¥, í™•ì¥ì„±, ì•ˆì •ì„±

#### 3. ëŒ€ê·œëª¨ ì—”í„°í”„ë¼ì´ì¦ˆ
**ì¶”ì²œ ìŠ¤íƒ**:
- ì‹¤í—˜ ê´€ë¦¬: W&B Enterprise
- ë°ì´í„° ê´€ë¦¬: Kubeflow
- ë°°í¬: Seldon Core
- ëª¨ë‹ˆí„°ë§: Prometheus + Grafana + Evidently

**ì´ìœ **: í™•ì¥ì„±, ì•ˆì •ì„±, ê³ ê¸‰ ê¸°ëŠ¥

---

## ğŸ¯ ì„ íƒ ê°€ì´ë“œ

### 1. ì˜ˆì‚° ê³ ë ¤ì‚¬í•­

**ë¬´ë£Œ ì˜µì…˜**:
- MLflow (ì‹¤í—˜ ê´€ë¦¬)
- DVC (ë°ì´í„° ê´€ë¦¬)
- FastAPI (ë°°í¬)
- Evidently AI (ëª¨ë‹ˆí„°ë§)

**ìœ ë£Œ ì˜µì…˜**:
- W&B (ì‹¤í—˜ ê´€ë¦¬ + ëª¨ë‹ˆí„°ë§)
- AWS SageMaker (í†µí•© í”Œë«í¼)
- Azure ML (í†µí•© í”Œë«í¼)

### 2. ê¸°ìˆ ì  ê³ ë ¤ì‚¬í•­

**ì´ˆë³´ì**:
- W&B (ì‚¬ìš© í¸ì˜ì„±)
- FastAPI (ê°„ë‹¨í•œ ë°°í¬)
- Evidently AI (ML íŠ¹í™”)

**ê³ ê¸‰ ì‚¬ìš©ì**:
- MLflow (ìœ ì—°ì„±)
- Kubeflow (í™•ì¥ì„±)
- Seldon Core (ê³ ê¸‰ ë°°í¬)

### 3. íŒ€ ê·œëª¨ë³„ ì¶”ì²œ

**1-5ëª… íŒ€**:
```
ì‹¤í—˜ ê´€ë¦¬: MLflow
ë°ì´í„° ê´€ë¦¬: DVC
ë°°í¬: FastAPI
ëª¨ë‹ˆí„°ë§: Evidently AI
```

**6-20ëª… íŒ€**:
```
ì‹¤í—˜ ê´€ë¦¬: W&B
ë°ì´í„° ê´€ë¦¬: DVC + Airflow
ë°°í¬: FastAPI + Docker
ëª¨ë‹ˆí„°ë§: Prometheus + Grafana
```

**20ëª… ì´ìƒ íŒ€**:
```
ì‹¤í—˜ ê´€ë¦¬: W&B Enterprise
ë°ì´í„° ê´€ë¦¬: Kubeflow
ë°°í¬: Seldon Core
ëª¨ë‹ˆí„°ë§: Prometheus + Grafana + Evidently
```

### 4. ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

**ë‹¨ê³„ì  ì ‘ê·¼**:
1. **1ë‹¨ê³„**: ê¸°ë³¸ ë„êµ¬ ë„ì… (MLflow, DVC)
2. **2ë‹¨ê³„**: ìë™í™” ì¶”ê°€ (Airflow, CI/CD)
3. **3ë‹¨ê³„**: ê³ ê¸‰ ê¸°ëŠ¥ ë„ì… (Kubeflow, Seldon)

**í†µí•© ê³ ë ¤ì‚¬í•­**:
- ë„êµ¬ ê°„ í˜¸í™˜ì„± í™•ì¸
- ë°ì´í„° í˜•ì‹ í‘œì¤€í™”
- API í†µí•© ê³„íš

---

## ğŸ“š ê²°ë¡ 

MLOps ë„êµ¬ ì„ íƒì€ í”„ë¡œì íŠ¸ì˜ ê·œëª¨, ì˜ˆì‚°, ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. 

**í•µì‹¬ ì›ì¹™**:
1. **ë‹¨ìˆœí•¨ë¶€í„° ì‹œì‘**: ë³µì¡í•œ ë„êµ¬ë³´ë‹¤ëŠ” í•„ìš”í•œ ê¸°ëŠ¥ë¶€í„°
2. **í™•ì¥ì„± ê³ ë ¤**: ë¯¸ë˜ ì„±ì¥ì„ ê³ ë ¤í•œ ì„ íƒ
3. **íŒ€ ì—­ëŸ‰ í‰ê°€**: í•™ìŠµ ê³¡ì„ ê³¼ íŒ€ ê¸°ìˆ  ìˆ˜ì¤€ ê³ ë ¤
4. **ë¹„ìš© íš¨ìœ¨ì„±**: ë¬´ë£Œ ë„êµ¬ë¡œ ì‹œì‘í•˜ì—¬ í•„ìš”ì‹œ ì—…ê·¸ë ˆì´ë“œ

**ì¶”ì²œ ì ‘ê·¼ë²•**:
1. **MVP êµ¬ì¶•**: ê¸°ë³¸ ë„êµ¬ë¡œ ì‹œì‘
2. **ì ì§„ì  ê°œì„ **: í•„ìš”ì— ë”°ë¼ ë„êµ¬ ì¶”ê°€
3. **ì§€ì†ì  í‰ê°€**: ì •ê¸°ì ì¸ ë„êµ¬ ê²€í†  ë° ì—…ë°ì´íŠ¸

ì´ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ í”„ë¡œì íŠ¸ì— ìµœì ì˜ MLOps ë„êµ¬ ìŠ¤íƒì„ êµ¬ì¶•í•˜ì„¸ìš”! 