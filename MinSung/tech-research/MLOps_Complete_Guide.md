# MLOps ì™„ì „ ê°€ì´ë“œ: ë¨¸ì‹ ëŸ¬ë‹ ìš´ì˜ì˜ ëª¨ë“  ê²ƒ

## ğŸ“‹ ëª©ì°¨
1. [MLOpsë€ ë¬´ì—‡ì¸ê°€?](#mlopsë€-ë¬´ì—‡ì¸ê°€)
2. [MLOpsì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ](#mlopsì˜-í•µì‹¬-êµ¬ì„±-ìš”ì†Œ)
3. [MLOps ìƒëª…ì£¼ê¸°](#mlops-ìƒëª…ì£¼ê¸°)
4. [ë„êµ¬ ë° ê¸°ìˆ  ìŠ¤íƒ](#ë„êµ¬-ë°-ê¸°ìˆ -ìŠ¤íƒ)
5. [ì‹¤ì œ êµ¬í˜„ ê°€ì´ë“œ](#ì‹¤ì œ-êµ¬í˜„-ê°€ì´ë“œ)
6. [ëª¨ë²” ì‚¬ë¡€](#ëª¨ë²”-ì‚¬ë¡€)
7. [ë¬¸ì œ í•´ê²° ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#ë¬¸ì œ-í•´ê²°-ë°-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ğŸ¯ MLOpsë€ ë¬´ì—‡ì¸ê°€?

### ì •ì˜
**MLOps (Machine Learning Operations)**ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ê°œë°œë¶€í„° ë°°í¬, ìš´ì˜ê¹Œì§€ì˜ ì „ì²´ ìƒëª…ì£¼ê¸°ë¥¼ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ë¡ ì…ë‹ˆë‹¤. DevOpsì˜ ì² í•™ì„ ë¨¸ì‹ ëŸ¬ë‹ì— ì ìš©í•œ ê²ƒìœ¼ë¡œ, ML ëª¨ë¸ì˜ ì§€ì†ì ì¸ í†µí•©, ë°°í¬, ëª¨ë‹ˆí„°ë§ì„ ìë™í™”í•©ë‹ˆë‹¤.

### MLOpsì˜ ëª©ì 
- **ì¬í˜„ ê°€ëŠ¥ì„±**: ë™ì¼í•œ ê²°ê³¼ë¥¼ ë³´ì¥í•˜ëŠ” ì‹¤í—˜ í™˜ê²½
- **ìë™í™”**: ìˆ˜ë™ ì‘ì—…ì„ ìµœì†Œí™”í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- **ëª¨ë‹ˆí„°ë§**: ëª¨ë¸ ì„±ëŠ¥ì˜ ì§€ì†ì ì¸ ì¶”ì 
- **í™•ì¥ì„±**: ëŒ€ê·œëª¨ ML ì‹œìŠ¤í…œì˜ íš¨ìœ¨ì  ê´€ë¦¬
- **í˜‘ì—…**: ë°ì´í„° ê³¼í•™ì, ì—”ì§€ë‹ˆì–´, ìš´ì˜íŒ€ ê°„ì˜ ì›í™œí•œ í˜‘ì—…

### MLOps vs DevOps
| êµ¬ë¶„ | DevOps | MLOps |
|------|--------|-------|
| **ì•„í‹°íŒ©íŠ¸** | ì½”ë“œ | ëª¨ë¸ + ë°ì´í„° + ì½”ë“œ |
| **í…ŒìŠ¤íŠ¸** | ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ |
| **ë°°í¬** | ì½”ë“œ ë°°í¬ | ëª¨ë¸ + ë°ì´í„° ë°°í¬ |
| **ëª¨ë‹ˆí„°ë§** | ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ | ëª¨ë¸ ì„±ëŠ¥ + ë°ì´í„° í’ˆì§ˆ |

---

## ğŸ”§ MLOpsì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ

### 1. ë°ì´í„° ê´€ë¦¬ (Data Management)
```python
# ì˜ˆì‹œ: DVCë¥¼ ì‚¬ìš©í•œ ë°ì´í„° ë²„ì „ ê´€ë¦¬
import dvc.api

# ë°ì´í„° ë¡œë“œ
data = dvc.api.read('data/raw/dataset.csv', repo='path/to/repo')
```

**ì£¼ìš” ê¸°ëŠ¥:**
- ë°ì´í„° ë²„ì „ ê´€ë¦¬ (DVC)
- ë°ì´í„° í’ˆì§ˆ ê²€ì¦
- ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìë™í™”
- ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€

### 2. ì‹¤í—˜ ê´€ë¦¬ (Experiment Management)
```python
# ì˜ˆì‹œ: MLflowë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ ì¶”ì 
import mlflow

with mlflow.start_run():
    # íŒŒë¼ë¯¸í„° ë¡œê¹…
    mlflow.log_param("learning_rate", 0.01)
    mlflow.log_param("batch_size", 32)
    
    # ëª¨ë¸ í•™ìŠµ
    model = train_model(X_train, y_train)
    
    # ë©”íŠ¸ë¦­ ë¡œê¹…
    accuracy = evaluate_model(model, X_test, y_test)
    mlflow.log_metric("accuracy", accuracy)
    
    # ëª¨ë¸ ì €ì¥
    mlflow.sklearn.log_model(model, "model")
```

**ì£¼ìš” ê¸°ëŠ¥:**
- ì‹¤í—˜ ì¶”ì  ë° ë¹„êµ
- í•˜ì´í¼íŒŒë¼ë¯¸í„° ê´€ë¦¬
- ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥
- ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ í™˜ê²½

### 3. ëª¨ë¸ ë°°í¬ (Model Deployment)
```python
# ì˜ˆì‹œ: FastAPIë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ ì„œë¹™
from fastapi import FastAPI
from pydantic import BaseModel
import joblib

app = FastAPI()

class PredictionRequest(BaseModel):
    features: list[float]

@app.post("/predict")
async def predict(request: PredictionRequest):
    model = joblib.load("model.pkl")
    prediction = model.predict([request.features])
    return {"prediction": prediction.tolist()}
```

**ì£¼ìš” ê¸°ëŠ¥:**
- REST API ì„œë¹™
- ì»¨í…Œì´ë„ˆí™” (Docker)
- A/B í…ŒìŠ¤íŠ¸
- ë¡¤ë°± ê¸°ëŠ¥

### 4. ëª¨ë‹ˆí„°ë§ (Monitoring)
```python
# ì˜ˆì‹œ: ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
import logging
from datetime import datetime

def log_prediction(features, prediction, actual=None):
    logging.info({
        "timestamp": datetime.now().isoformat(),
        "features": features,
        "prediction": prediction,
        "actual": actual,
        "model_version": "v1.0.0"
    })
```

**ì£¼ìš” ê¸°ëŠ¥:**
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€
- ëª¨ë¸ ì„±ëŠ¥ ì•Œë¦¼
- ë¡œê·¸ ë¶„ì„

---

## ğŸ”„ MLOps ìƒëª…ì£¼ê¸°

### 1. ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬
```python
# ì˜ˆì‹œ: ë°ì´í„° íŒŒì´í”„ë¼ì¸
from pathlib import Path
import pandas as pd
from sklearn.preprocessing import StandardScaler

def load_and_preprocess_data(data_path: Path) -> tuple[pd.DataFrame, pd.DataFrame]:
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(data_path)
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    df = df.fillna(df.mean())
    
    # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
    scaler = StandardScaler()
    features = scaler.fit_transform(df.drop('target', axis=1))
    
    return features, df['target']
```

### 2. ëª¨ë¸ ê°œë°œ ë° ì‹¤í—˜
```python
# ì˜ˆì‹œ: ì‹¤í—˜ íŒŒì´í”„ë¼ì¸
import mlflow
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

def run_experiment(X_train, y_train, params: dict):
    """MLflowë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ ì‹¤í–‰"""
    with mlflow.start_run():
        # íŒŒë¼ë¯¸í„° ë¡œê¹…
        mlflow.log_params(params)
        
        # ëª¨ë¸ í•™ìŠµ
        model = RandomForestClassifier(**params)
        scores = cross_val_score(model, X_train, y_train, cv=5)
        
        # ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metric("cv_accuracy", scores.mean())
        mlflow.log_metric("cv_std", scores.std())
        
        # ëª¨ë¸ ì €ì¥
        mlflow.sklearn.log_model(model, "model")
        
        return model, scores.mean()
```

### 3. ëª¨ë¸ ê²€ì¦ ë° í…ŒìŠ¤íŠ¸
```python
# ì˜ˆì‹œ: ëª¨ë¸ ê²€ì¦
def validate_model(model, X_test, y_test, threshold: float = 0.8):
    """ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦"""
    predictions = model.predict(X_test)
    accuracy = (predictions == y_test).mean()
    
    if accuracy < threshold:
        raise ValueError(f"Model accuracy {accuracy:.3f} below threshold {threshold}")
    
    return accuracy
```

### 4. ëª¨ë¸ ë°°í¬
```python
# ì˜ˆì‹œ: Dockerë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ ë°°í¬
# Dockerfile
"""
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
"""
```

### 5. ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜
```python
# ì˜ˆì‹œ: ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€
from scipy import stats

def detect_data_drift(reference_data, current_data, threshold: float = 0.05):
    """ë°ì´í„° ë“œë¦¬í”„íŠ¸ íƒì§€"""
    # Kolmogorov-Smirnov í…ŒìŠ¤íŠ¸
    statistic, p_value = stats.ks_2samp(reference_data, current_data)
    
    if p_value < threshold:
        return True, p_value
    return False, p_value
```

---

## ğŸ› ï¸ ë„êµ¬ ë° ê¸°ìˆ  ìŠ¤íƒ

### ë°ì´í„° ê´€ë¦¬
| ë„êµ¬ | ìš©ë„ | ì¥ì  |
|------|------|------|
| **DVC** | ë°ì´í„° ë²„ì „ ê´€ë¦¬ | Gitê³¼ í†µí•©, ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ |
| **Apache Airflow** | ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ | ë³µì¡í•œ íŒŒì´í”„ë¼ì¸, ìŠ¤ì¼€ì¤„ë§ |
| **Great Expectations** | ë°ì´í„° í’ˆì§ˆ ê²€ì¦ | ìë™í™”ëœ ë°ì´í„° ê²€ì¦ |

### ì‹¤í—˜ ê´€ë¦¬
| ë„êµ¬ | ìš©ë„ | ì¥ì  |
|------|------|------|
| **MLflow** | ì‹¤í—˜ ì¶”ì  | í†µí•©ëœ í”Œë«í¼, ë‹¤ì–‘í•œ ML ë¼ì´ë¸ŒëŸ¬ë¦¬ ì§€ì› |
| **Weights & Biases** | ì‹¤í—˜ ê´€ë¦¬ | ì‹œê°í™”, í˜‘ì—… ê¸°ëŠ¥ |
| **Kubeflow** | ML ì›Œí¬í”Œë¡œìš° | Kubernetes ê¸°ë°˜, í™•ì¥ì„± |

### ëª¨ë¸ ë°°í¬
| ë„êµ¬ | ìš©ë„ | ì¥ì  |
|------|------|------|
| **FastAPI** | API ì„œë¹™ | ê³ ì„±ëŠ¥, ìë™ ë¬¸ì„œí™” |
| **Docker** | ì»¨í…Œì´ë„ˆí™” | ì¼ê´€ëœ í™˜ê²½, ì´ì‹ì„± |
| **Kubernetes** | ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | í™•ì¥ì„±, ê³ ê°€ìš©ì„± |

### ëª¨ë‹ˆí„°ë§
| ë„êµ¬ | ìš©ë„ | ì¥ì  |
|------|------|------|
| **Prometheus** | ë©”íŠ¸ë¦­ ìˆ˜ì§‘ | ì‹œê³„ì—´ ë°ì´í„°, ì•Œë¦¼ |
| **Grafana** | ì‹œê°í™” | ëŒ€ì‹œë³´ë“œ, ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ |
| **Evidently AI** | ML ëª¨ë‹ˆí„°ë§ | ë°ì´í„° ë“œë¦¬í”„íŠ¸, ëª¨ë¸ ì„±ëŠ¥ |

---

## ğŸš€ ì‹¤ì œ êµ¬í˜„ ê°€ì´ë“œ

### 1. í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì •
```
mlops-project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ .gitignore
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â””â”€â”€ validation.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ training.py
â”‚   â”‚   â””â”€â”€ evaluation.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ drift_detection.py
â”œâ”€â”€ tests/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### 2. CI/CD íŒŒì´í”„ë¼ì¸ ì„¤ì •
```yaml
# .github/workflows/mlops-pipeline.yml
name: MLOps Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Run tests
      run: |
        pytest tests/
    
    - name: Run linting
      run: |
        ruff check src/
        black --check src/

  build-and-deploy:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
    - uses: actions/checkout@v2
    
    - name: Build Docker image
      run: |
        docker build -t mlops-model .
    
    - name: Deploy to production
      run: |
        # ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
```

### 3. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì„¤ì •
```python
# ì˜ˆì‹œ: Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •
import requests
import json

def setup_monitoring_dashboard():
    """ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì„¤ì •"""
    dashboard = {
        "dashboard": {
            "title": "ML Model Monitoring",
            "panels": [
                {
                    "title": "Model Accuracy",
                    "type": "graph",
                    "targets": [
                        {
                            "expr": "model_accuracy",
                            "legendFormat": "Accuracy"
                        }
                    ]
                },
                {
                    "title": "Data Drift Score",
                    "type": "graph",
                    "targets": [
                        {
                            "expr": "data_drift_score",
                            "legendFormat": "Drift Score"
                        }
                    ]
                }
            ]
        }
    }
    
    # Grafana APIë¥¼ í†µí•´ ëŒ€ì‹œë³´ë“œ ìƒì„±
    response = requests.post(
        "http://grafana:3000/api/dashboards/db",
        json=dashboard,
        headers={"Authorization": "Bearer YOUR_API_KEY"}
    )
    
    return response.json()
```

---

## ğŸ“Š ëª¨ë²” ì‚¬ë¡€

### 1. ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬
```python
# ì˜ˆì‹œ: íƒ€ì… íŒíŒ…ê³¼ ë¬¸ì„œí™”
from typing import List, Dict, Optional
import logging

def preprocess_features(
    data: pd.DataFrame,
    feature_columns: List[str],
    target_column: str
) -> tuple[np.ndarray, np.ndarray]:
    """
    íŠ¹ì„± ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        data: ì…ë ¥ ë°ì´í„°í”„ë ˆì„
        feature_columns: ì‚¬ìš©í•  íŠ¹ì„± ì»¬ëŸ¼ ëª©ë¡
        target_column: íƒ€ê²Ÿ ì»¬ëŸ¼ëª…
        
    Returns:
        ì „ì²˜ë¦¬ëœ íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë°ì´í„°
        
    Raises:
        ValueError: í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°
    """
    logger = logging.getLogger(__name__)
    
    # ì…ë ¥ ê²€ì¦
    missing_columns = set(feature_columns + [target_column]) - set(data.columns)
    if missing_columns:
        raise ValueError(f"Missing columns: {missing_columns}")
    
    # íŠ¹ì„± ì „ì²˜ë¦¬
    features = data[feature_columns].values
    targets = data[target_column].values
    
    logger.info(f"Preprocessed {len(features)} samples with {len(feature_columns)} features")
    
    return features, targets
```

### 2. ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…
```python
# ì˜ˆì‹œ: ì²´ê³„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬
import logging
from functools import wraps

def handle_ml_errors(func):
    """ML í•¨ìˆ˜ì˜ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        logger = logging.getLogger(func.__module__)
        try:
            result = func(*args, **kwargs)
            logger.info(f"{func.__name__} completed successfully")
            return result
        except Exception as e:
            logger.error(f"Error in {func.__name__}: {str(e)}")
            raise
    return wrapper

@handle_ml_errors
def train_model(X_train, y_train, model_params):
    """ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜"""
    # ëª¨ë¸ í•™ìŠµ ë¡œì§
    pass
```

### 3. ì„¤ì • ê´€ë¦¬
```yaml
# config/config.yaml
data:
  raw_data_path: "data/raw/"
  processed_data_path: "data/processed/"
  train_test_split: 0.8

model:
  algorithm: "random_forest"
  hyperparameters:
    n_estimators: 100
    max_depth: 10
    random_state: 42

training:
  cv_folds: 5
  scoring_metric: "accuracy"
  min_accuracy_threshold: 0.8

deployment:
  api_host: "0.0.0.0"
  api_port: 8000
  model_path: "models/"

monitoring:
  drift_threshold: 0.25
  performance_threshold: 0.8
  check_interval_hours: 24
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²° ë° íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. ëª¨ë¸ ì„±ëŠ¥ ì €í•˜
**ì¦ìƒ**: ë°°í¬ëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì ì§„ì ìœ¼ë¡œ ì €í•˜
**í•´ê²°ì±…**:
```python
def diagnose_model_degradation():
    """ëª¨ë¸ ì„±ëŠ¥ ì €í•˜ ì§„ë‹¨"""
    # 1. ë°ì´í„° ë“œë¦¬í”„íŠ¸ í™•ì¸
    drift_score = calculate_data_drift()
    
    # 2. íŠ¹ì„± ì¤‘ìš”ë„ ë³€í™” í™•ì¸
    feature_importance_change = compare_feature_importance()
    
    # 3. ëª¨ë¸ ì¬í›ˆë ¨ í•„ìš”ì„± íŒë‹¨
    if drift_score > 0.25 or feature_importance_change > 0.1:
        trigger_retraining()
```

#### 2. ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨
**ì¦ìƒ**: ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì˜¤ë¥˜ ë°œìƒ
**í•´ê²°ì±…**:
```python
def robust_data_pipeline():
    """ê²¬ê³ í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸"""
    try:
        # ë°ì´í„° ê²€ì¦
        validate_data_quality()
        
        # ì „ì²˜ë¦¬ ì‹¤í–‰
        processed_data = preprocess_data()
        
        # ê²°ê³¼ ê²€ì¦
        validate_processed_data(processed_data)
        
        return processed_data
        
    except Exception as e:
        # ì‹¤íŒ¨ ì‹œ ì´ì „ ë²„ì „ ì‚¬ìš©
        logger.warning(f"Pipeline failed, using previous version: {e}")
        return load_previous_version()
```

#### 3. API ì‘ë‹µ ì§€ì—°
**ì¦ìƒ**: ëª¨ë¸ ì˜ˆì¸¡ APIì˜ ì‘ë‹µ ì‹œê°„ ì¦ê°€
**í•´ê²°ì±…**:
```python
# ë¹„ë™ê¸° ì²˜ë¦¬ ë° ìºì‹±
from functools import lru_cache
import asyncio

@lru_cache(maxsize=1000)
def cached_prediction(features_tuple):
    """ì˜ˆì¸¡ ê²°ê³¼ ìºì‹±"""
    return model.predict([list(features_tuple)])

async def predict_async(request: PredictionRequest):
    """ë¹„ë™ê¸° ì˜ˆì¸¡ ì²˜ë¦¬"""
    features_tuple = tuple(request.features)
    
    # ìºì‹œëœ ê²°ê³¼ í™•ì¸
    if features_tuple in cached_prediction.cache_info():
        return {"prediction": cached_prediction(features_tuple)}
    
    # ìƒˆë¡œìš´ ì˜ˆì¸¡ ìˆ˜í–‰
    prediction = await asyncio.to_thread(cached_prediction, features_tuple)
    return {"prediction": prediction}
```

### ì„±ëŠ¥ ìµœì í™” íŒ

#### 1. ëª¨ë¸ ìµœì í™”
```python
# ëª¨ë¸ ì–‘ìí™” ì˜ˆì‹œ
import onnxruntime as ort

def optimize_model_for_production(model, X_sample):
    """í”„ë¡œë•ì…˜ìš© ëª¨ë¸ ìµœì í™”"""
    # ONNX ë³€í™˜
    import onnx
    from skl2onnx import convert_sklearn
    
    onx = convert_sklearn(model, initial_types=[('float_input', FloatTensorType([None, X_sample.shape[1]]))])
    
    # ìµœì í™”ëœ ì„¸ì…˜ ìƒì„±
    session = ort.InferenceSession(onx.SerializeToString())
    
    return session
```

#### 2. ë°°ì¹˜ ì²˜ë¦¬
```python
# ë°°ì¹˜ ì˜ˆì¸¡ ì²˜ë¦¬
def batch_predict(model, features_batch, batch_size=100):
    """ë°°ì¹˜ ë‹¨ìœ„ ì˜ˆì¸¡ ì²˜ë¦¬"""
    predictions = []
    
    for i in range(0, len(features_batch), batch_size):
        batch = features_batch[i:i + batch_size]
        batch_predictions = model.predict(batch)
        predictions.extend(batch_predictions)
    
    return predictions
```

---

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

### ì¶”ì²œ ë„ì„œ
1. **"MLOps Engineering at Scale"** - Carl Osipov
2. **"Building Machine Learning Pipelines"** - Hannes Hapke
3. **"Practical MLOps"** - Noah Gift

### ì˜¨ë¼ì¸ ë¦¬ì†ŒìŠ¤
- [MLOps Community](https://mlops.community/)
- [Papers With Code - MLOps](https://paperswithcode.com/task/mlops)
- [Google Cloud MLOps](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)

### ì‹¤ìŠµ í”„ë¡œì íŠ¸
1. **ê¸°ë³¸ MLOps íŒŒì´í”„ë¼ì¸ êµ¬ì¶•**
2. **ì‹¤ì‹œê°„ ëª¨ë¸ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ**
3. **A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬**
4. **ìë™í™”ëœ ëª¨ë¸ ì¬í›ˆë ¨ ì‹œìŠ¤í…œ**

---

## ğŸ¯ ê²°ë¡ 

MLOpsëŠ” ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ì˜ ì„±ê³µì„ ìœ„í•œ í•„ìˆ˜ ìš”ì†Œì…ë‹ˆë‹¤. ì²´ê³„ì ì¸ ì ‘ê·¼ê³¼ ì ì ˆí•œ ë„êµ¬ ì„ íƒì„ í†µí•´ ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ML ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•µì‹¬ í¬ì¸íŠ¸:**
- ìë™í™”ëœ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
- ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ì•Œë¦¼
- ì¬í˜„ ê°€ëŠ¥í•œ ì‹¤í—˜ í™˜ê²½
- í˜‘ì—…ì„ ìœ„í•œ ëª…í™•í•œ í”„ë¡œì„¸ìŠ¤
- í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„

ì´ ê°€ì´ë“œë¥¼ ì°¸ê³ í•˜ì—¬ ìì‹ ë§Œì˜ MLOps ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ì„¸ìš”! 